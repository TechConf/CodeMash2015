As an industry we are collecting more and more data. At some point we have to be able to make sense of the data. Unfortunately many of the tools we have historically used can not scale up to the terabytes and petabytes we have captured. Hadoop is one of those relatively new technologies that is taking the industry by storm since it has proven to scale by taking advantage of the MapReduce pattern and distributed computing. During this hands-on tutorial you will provision a Hadoop cluster, write MapReduce jobs and learn how to store and access data via Hadoop Distributed File System (HDFS). You will also learn how cloud providers such as Amazon Web Services’ Elastic MapReduce (EMR) and Microsoft’s Azure HDInsight provide Hadoop as a service.

============

[Slides] (https://s3.amazonaws.com/cmj-presentations/hadoop-codemash-2015/index.html)

Follow me on Twitter at http://twitter.com/javajudd


